\section{Banach fixed point Theorem}


\begin{exercise}{1}
Give further examples of mappings of elementary geometry which have
\begin{enumerate}
    \item a single point,
    \item infinitely many fixed points.
\end{enumerate}
\end{exercise}
\begin{proof}
\begin{enumerate}
    \item The identity mapping has infinitely many fixed points.
    \item Square roots, as a function on $\R_+$ has one fixed point.
\end{enumerate}
\end{proof} 

\begin{exercise}{3}
Illustrate with an example that in Theorem 5.1-2, completeness is essential and cannot be omitted.
\end{exercise}
\begin{proof}
Consider $f: (0,1) \to (0,1)$ given by $f(x) = x^2$.
$(0,1)$ is not complete, and $f$ has one fixed point which is not part of its domain, namely 0.
\end{proof} 

\begin{exercise}{4}
It is important that in Banach's Theorem 5.1-2, the condition (1) cannot be replaced by $d(Tx, Ty) < d(x,y)$ when $x \neq y$.
To see this, consider $X = \set{x: 1 \leq x < \infty}$, taken with the usual metric of the real line and $T: X \to X$ defined by $x \mapsto x + x^{-1}$.
Show that $\absoluteValue{Tx - Ty} < \absoluteValue{x - y}$ when $x \neq y$, but the mapping has no fixed points.
\end{exercise}
\begin{proof}
Notice that $T' = 1 - x^{-2}$, which is less than 1 for all $x \in X$.
for $x, y \in X$, we can then apply the mean value Theorem to $T$, to conclude there exists $c \in [x,y]$, such that the following holds:
\begin{align*}
    \frac{\absoluteValue{Tx - Ty}}{\absoluteValue{x - y}} = \absoluteValue{T'(c)} < 1,
\end{align*}
so that multiplying both sides of the inequality by $\absoluteValue{x - y}$, gives us the desired result.
Since $T$ is increasing and the hypothesis holds, then $T$ cannot have a fixed point, completing the proof.
\end{proof} 

\begin{exercise}{5}
If $T: X \to X$ satisfies $d(Tx, Ty) < d(x,y)$ when $x \neq y$ and $T$ has a fixed point, show that the fixed point is unique;
here, $(X, d)$ is a metric space.
\end{exercise}
\begin{proof}
Let $x$ and $x'$ be fixed points, then $d(x, x') = d(Tx, Tx') < d(x, x')$, where the last inequality follows by assumption, a contradiction, so that $x = x'$.
\end{proof} 

\begin{exercise}{7}
Prove that a contraction $T$ on a metric space $X$ is a continuous mapping.
\end{exercise}
\begin{proof}
Let $\epsilon > 0$, and let $d(x, y) < \delta = \epsilon$, we have $d(Tx, Ty) < ad(x, y) < d(x, y) < \epsilon$, so that $T$ is continuous.
\end{proof} 

\begin{exercise}{8}
Show that the error bounds given by $d(x_m, x) \leq \frac{a^m}{1-a} d(x_0, x_1)$ form a proper monotone decreasing sequence.
Show that $d(x_m, x) \leq \frac{a}{1-a} d(x_{m-1}, x_m)$ is at least as good as $d(x_m, x) \leq \frac{a^m}{1-a} d(x_0, x_1)$.
\end{exercise}
\begin{proof}
($d(x_m, x) \leq \frac{a^m}{1-a} d(x_0, x_1)$ is decreasing)
Notice that $1/(1-a)$ and $d(x_0, x_1)$ are fixed, so that the only factor affecting the bound, as $n$ increases is $a^n$.
Since $a < 1$, $a^n > a^{n+1}$, so that the bound is monotonically decreasing.

($d(x_m, x) \leq \frac{a}{1-a} d(x_{m-1}, x_m)$ is at least as good as $d(x_m, x) \leq \frac{a^m}{1-a} d(x_0, x_1)$)
We have
\begin{align*}
    \frac{a}{1-a} d(x_{m-1}, x_m)
    \leq& \frac{a}{1-a} d(Tx_{m-2}, Tx_{m-1})\\
    \leq& \frac{a^2}{1-a} d(x_{m-2}, x_{m-1})\\
    \leq& \dots\\
    \leq& \frac{a^m}{1-a} d(x_0, x_1),
\end{align*}
completing the proof.
\end{proof} 

\begin{exercise}{9}
Show that in the case of Theorem 5.1-4 we have the prior error estimate $d(x_m, x) < a^m r$, and the posterior estimate $d(x_m, x) \leq \frac{a}{1-a} d(x_{m-1}, x_m)$.
\end{exercise}
\begin{proof}
Notice that we applied Banach's Theorem for the proof of 5.1-4, so that the bounds derived in 5.1-3 apply.
Thus there is nothing to prove for the second bound.
For the first one, by assumption, we have $d(x_0, Tx_0) = d(x_0, x_1) < (1-a)r$, so that using the bound derived in 5.1-3, we obtain $d(x_m, x) \leq \frac{a^m}{1-a}d(x_0, x_1) < \frac{a^m}{1-a}(1-a)r$, completing the proof.
\end{proof} 

\begin{exercise}{10}
In analysis, a usual sufficient condition for the convergence of an iteration $x_n = g(x_{n-1})$ is that $g$ be continuously  differentiable and $\absoluteValue{g'(x)} \leq a < 1$.
Verify this by the use of Banach's fixed point Theorem.
\end{exercise}
\begin{proof}
Since $g$ is continuously differentiable, we can apply the mean value Theorem, so that for any $x, y \in \R$, there exists a $c \in [x, y]$ with $\absoluteValue{g(x) - g(y)}/\absoluteValue{x - y} = \absoluteValue{g'(c)} \leq a$, so that $\absoluteValue{g(x) - g(y)} \leq a \absoluteValue{x - y}$, where $a < 1$ by assumption.
Thus, $g$ is a contraction and we can apply Banach's fixed point Theorem, completing the proof.
\end{proof} 

\begin{exercise}{11}
To find approximate numerical solutions of a given equation $f(x) = 0$, we may convert the equation to the form $x = g(x)$, choose an initial value $x_0$ and compute $x_n = g(x_{n-1})$ for $n = 1, 2, \dots$.

Suppose that $g$ is continuously differentiable on some interval $J = [x_0 - r, x_0 + r]$ and satisfies $\absoluteValue{g'(x)} \leq a < 1$ on $J$ as well as $\absoluteValue{g(x_0) - x_0} < (1-a)r$.

Show that then $x = g(x)$ has a unique solution $x$ on $J$, the iterative sequence $(x_m)$ converges to that solution, and one has the error estimates $\absoluteValue{x - x_m} < a^m r$, $\absoluteValue{x - x_m} \leq (a/(1-a)) \absoluteValue{x_m - x_{m-1}}$.
\end{exercise}
\begin{proof}
This is a Corollary to Theorem 5.1-4 and exercises 9 and 10, where $X = \R$ and $Y = [x_0 - r, x_0 + r]$.
\end{proof} 

\begin{exercise}{12}
Using Banach's Theorem 5.1-2, set up an iteration process for solving $f(x) = 0$ if $f$ is continuously differentiable on an interval $J = [a,b]$, $f(a) < 0$, $f(b) > 0$ and $0 < k_1 \leq f'(x) \leq k_2$, $x \in J$;
use $g(x) = x - \lambda f(x)$ with a suitable $\lambda$.
\end{exercise}
\begin{proof}
We want to build a contraction based on the hinted function $g(x)$.
To do this, we have to find a $\lambda$, so that $\absoluteValue{g'(x)} \leq a < 1$.
We have that $g'(x) = 1 - \lambda f'(x)$, so that choosing $\lambda = \epsilon/k_2$, with $\epsilon \in (0,1)$ does the job, as then we would have $g'(x) = 1 - \lambda f'(x) \leq 1 - \epsilon k_2/k_2 = 1 - \epsilon < 1$.
Applying exercise 10 gives us the desired result.
\end{proof} 

\begin{exercise}{15 (Newton's method)}
Let $f$ be real-valued and twice continuously differentiable on an interval $[a,b]$, and let $x'$ be a simple zero of $f$ in $(a,b)$ (a simple zero is a point such that $f(x') = 0$ and $f'(x') \neq 0$, which geometrically means that the function crosses the axis at $x'$ instead of just touching it).
Show that Newton's method defined by $x_{n+1} = g(x_n)$, $g(x_n) = x_n - f(x_n)/f'(x_n)$ is a contraction in some neighborhood of $x'$ (so that the iterative sequence converges to $x'$ for any $x_0$ sufficiently close to $x'$).
\end{exercise}
\begin{proof}
To apply exercise 10, we have to prove $\absoluteValue{g'(x)} < 1$.
First, consider the derivative of $g$:
\begin{align*}
    g'(x)
    = 1 - \parens{\frac{f'(x)^2 - f''(x) f(x)}{f'(x)^2}}
    = 1 - 1 + \frac{f''(x) f(x)}{f'(x)^2}
    \leq M f(x),
\end{align*}
where $M = \max_{x \in [a,b]} f''(x)/f'(x)^2$.

Furthermore, since $f$ is continuously differentiable, we can take any $[x, x']$, where $x \in [a,b]$, and find a $c \in [x, x']$ so that the following holds $\absoluteValue{f(x) - f(x')} = \absoluteValue{f'(c)}\absoluteValue{x - x'}$.
Using this fact, we obtain:
\begin{align*}
    \absoluteValue{f(x)}
    = \absoluteValue{f(x) - f(x')}
    = \absoluteValue{f'(c)} \absoluteValue{x - x'}
    = K \absoluteValue{x - x'}.
\end{align*}

Replacing this in the equality we found above, we get that $\absoluteValue{g'(x)} \leq MK \absoluteValue{x - x'}$ so that if $\absoluteValue{x - x'} < 1/MK$ we get a contraction, allowing us to apply exercise 10, as required.
\end{proof} 

\begin{exercise}{16 (Square root)}
Show that an iteration for calculating the square root of a given positive number $c$ is $x_{n+1} = g(x_n) = (1/2)(x_n + c/x_n)$, where $n = 0, 1, \dots$.
What condition do we get from exercise 10?
Starting from $x_0 = 1$ calculate approximations $x_1, \dots, x_4$ for $\sqrt{2}.$
\end{exercise}
\begin{proof}
We will begin with the conditions and then using exercise 10, and the fact that $g$ has a fixed point we will prove it calculates the square root of $c$.

We begin by proving that $\absoluteValue{g'(x)} < 1$.
To see this, notice that
\begin{align*}
    \absoluteValue{g'(x)}
    = \absoluteValue{\frac{1}{2}\parens{1 - \frac{c}{x^2}}},
\end{align*}
which is less than 1 as long as $\absoluteValue{x^2 - c} < \absoluteValue{2x^2}$.

Now, if the condition holds, let $x$ be a fixed point of $g$.
Then $g(x) = x = (1/2)(x + c/x)$ which implies $2x^2 = x^2 + c$;
that is $x^2 = c$, so that $x$ computes the square root of $c$.

The first couple of iterations for the square root of 2 are
$x_0 = 1$, $x_1 = (1/2)(1+(2/1)) = 3/2$, $x_2 = (1/2)((3/2) + 2/(3/2)) = (1/2)((3/2) + (4/3)) = 21/12$.
\end{proof} 
