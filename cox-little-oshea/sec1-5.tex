\subsection{Polynomials of one variable}

6
7
10
11
14
16
17 (use a computer algebra system)

\begin{exercise}{1}
Over the complex numbers $\C$, Corollary 3 can be stated in a stronger form. Namely, prove that if $f\in\C[x]$ is a polynomial of degree $n>0$, then $f$ can be written in the form $f=c(x-a_1)\dots(x-a_n)$, where $c,a_1,\dots,a_n\in\C$ and $c\neq 0$. Hint: Use Theorem 7 of 1.1. Note that this result holds for any algebraically closed field.
\end{exercise}
\begin{proof}
First we recall that Theorem 7 of section 1.1 says that every nonconstant polynomial in $\C[x]$ has a root in $\C$. With this, let $f\in\C[x]$ be a polynomial of degree $n>0$ so that $f$ is nonconstant and we can apply Theorem 1.1.7. Let $a_1\in\C$ be a root of $f$, and divide $f$ by $x-a_1$. We obtain $f(x)=(x-a_1)q(x)+r(x)$. Since $0\leq\deg r<\deg (x-a)=1$, then $r$ is either a nonzero constant, or 0, but we have that $0 =f(a_1) =(x-a_1)q(a_1)+r(a_1) =r(a_1)$, which is not possible if $r$ is a nonzero constant. Continue the process until the quotient $q(x)$ quotient is constant. By renaming the last quotient $c$, we obtain the desired result.
\end{proof}

\begin{exercise}{2}
Although Corollary $3$ is simple to prove, it has some nice consequences. For example, consider the $n\times n$ Vandermonde determinant detemrined by $a_1,...,a_n$ in a field $k$:
$$\det\left(\begin{array}{ccccc}
1 & a_1 & a_1^2 & \hdots & a_1^{n-1}\\
1 & a_2 & a_2^2 & \hdots & a_2^{n-1}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
1 & a_n & a_n^2 & \hdots & a_n^{n-1}
\end{array}\right).$$
Prove that this determinant is nonzero when the $a_i$'s are distinct.
\end{exercise}
\begin{proof}
    Assume that the determinant is zero, then we know that the columns are linearly dependent. Thus there exists constants $\lambda_0,...,\lambda_{n-1}$, not all zero, such that
    $$\lambda_0\left(\begin{array}{c} 1\\ 1\\ \vdots\\ 1\end{array}\right) + \lambda_1\left(\begin{array}{c} a_1\\ a_2\\ \vdots\\ a_2\end{array}\right) + \lambda_2\left(\begin{array}{c} a_1^2\\ a_2^2\\ \vdots\\ a_n^2\end{array}\right) + \hdots + \lambda_{n-1}\left(\begin{array}{c} a_1^{n-1}\\ a_2^{n-1}\\ \vdots\\ a_n^{n-1}\end{array}\right) = \left(\begin{array}{c} 0\\ 0\\ \vdots\\ 0\end{array}\right).$$
    This gives the following system of equations:
    $$\left\{\begin{array}{lll}
    \lambda_0 + \lambda_1 a_1 + \lambda_2 a_2^2 + \hdots + \lambda_{n-1} a_1^{n-1} & = & 0\\
    \lambda_0 + \lambda_1 a_1 + \lambda_2 a_2^2 + \hdots + \lambda_{n-1} a_2^{n-1} & = & 0\\
    & \vdots & \\
    \lambda_0 + \lambda_1 a_n + \lambda_2 a_n^2 + \hdots + \lambda_{n-1} a_n^{n-1} & = & 0\\
   \end{array}\right.$$
   In other words, the polynomial $\lambda_0 + \lambda_1 x + \lambda_2 x^2 + ... + \lambda_{n-1}x^{n-1}$ has $n$ distinct roots, namely $a_1,...,a_n$. But this is one root more than its multiplicity, which has to imply $\lambda_0 = \lambda_1 = ... = \lambda_{n-1}$, which is a contradiction. We get that the determinant must be nonero.
\end{proof}

\begin{exercise}{3}
The fact that every ideal of $k[x]$ is principal (generated by one element) is special to the case of polynomials of one variable. In this exercise we will see why. Namely, consider the ideal $I = \langle x,y\rangle\subseteq k[x,y]$. Prove that $I$ is not a principal ideal.
\end{exercise}
\begin{proof}
    Assume that $\langle f\rangle = \langle x,y\rangle$. We know then that there is some $g$ such that $fg = x$. By comparing degrees of both sides, we see that $f$ must have degree $0$ or degree $1$. But if $f$ has degree $0$, then $\langle f\rangle = k[x,y]$, which is not true. So $f$ has the form $Ax+By+C$. We also know that $g$ must be a constant, so $g = D$. Thus
    $$x = ADx + BDy + CD.$$
    We get that $AD = 1$, $BD = CD = 0$. Thus $B=D = 0$. So our generator has the form $Ax$. But there is no polynomial $h$ such that $fh = y$. Thus $y\notin \langle f\rangle = \langle x,y\rangle$, which is a contradiction.
\end{proof}

\begin{exercise}{4}
If $h$ is the gcd of $f,g\in k[x]$, then prove that there are $A,B\in k[x]$ such that $Af+Bg = h$.    
\end{exercise}
\begin{proof}
    From Proposition $6$, we know that $h=\gcd(f,g)$ is the generator of the ideal $\langle f,g\rangle$. In particular, we know that $h\in \langle f,g\rangle$. This implies directly that there are $A$ and $B$ in $k[x]$ such that $h=Af+Bg$.
\end{proof}

\begin{exercise}{5}
If $f,g\in k[x]$, then prove that $\langle f-qg, g\rangle = \langle f,g\rangle$ for any $q$ in $k[x]$. This will prove equation (4) in the text.
\end{exercise}
\begin{proof}
    We see clearly that $f-qg \in \langle f,g\rangle$ and trivially $g\in \langle f,g\rangle$. Thus $\langle f-qg,g\rangle \subseteq \langle f,g\rangle$. Similarly, $f = (f-qg) + qg\in \langle f-qg,g\rangle$ and again trivially $g\in \langle f-qg,g\rangle$. Thus $\langle f,g\rangle\subseteq \langle f-qg,g\rangle$. We obtain $\langle f-qg,g\rangle = \langle f,g\rangle$.
\end{proof}

\begin{exercise}{6}
Given $f_1,\dots,f_x\in k[x]$, let $h=\gcd(f_2,\dots,f_s)$. Then use the equality $\brackets{h}=\brackets{f_2,\dots,f_s}$ to show that $\brackets{f_1,h}=\brackets{f_1,f_2,\dots,f_s}$. This equality is used in the proof of part (iii) of Proposition 8.
\end{exercise}
\begin{proof}
Clearly, $f_1\in \langle f_1,...,f_s\rangle$. Since $\langle h\rangle = \langle f_2,...,f_s\rangle$, and thus $h\in \langle f_2,...,f_s\rangle$. We see that $h = A_2 f_2 + ... + A_s f_s$. Thus, $h\in \langle f_1,...,f_s\rangle$. We get $\langle f_1,h\rangle\subseteq \langle f_1,f_2,...,f_s\rangle$. Conversely, it is trivial that $f_1\in \langle f_1,h\rangle$. Next, take $f_k$ with $2\leq k\leq s$, then $f_k\in \langle f_2,...,f_s\rangle = \langle h\rangle$. Thus $f_k = Ah$, and thus $f_k\in\langle f_1,h\rangle$. We obtain then that $\langle f_1,...,f_s\rangle \subseteq \langle f_1,h\rangle$, and thus $\langle f_1,...,f_s\rangle = \langle f_1,h\rangle$.
\end{proof}

\begin{exercise}{7}
If you are allowed to compute the $\gcd$ of only two polynomials at a time (which is true for some computer algebra systems), give pseudocode for an algorithm that computes the $\gcd$ of polynomials $f_1,\dots,f_s\in k[x]$, where $s>2$. Prove that your algorithm works. Hint: See Proposition 6. This will complete the proof of part (iv) of Proposition 8.
\end{exercise}
\begin{proof}
To compute $\gcd(f_1,...,f_s)$, we do the following. We take as input $f_1,...,f_s$ and $s\geq 1$. Then
\begin{center}
\begin{algorithmic}
\STATE $\text{res}\gets f_1$
\STATE $i\gets 2$
\WHILE{$i\leq s$}
    \STATE $\text{res}\gets \gcd(\text{res}, f_i)$
    \STATE $i\gets i+1$
\ENDWHILE
\end{algorithmic}
\end{center}
This algorithm works because at every step it computes
$$\text{res} = \gcd(f_1,\gcd(f_2,....,\gcd(f_{i-1},f_i))) = \gcd(f_1,...,f_i).$$
\end{proof}

\begin{exercise}{8}
Use a computer algebra system to compute the following gcd's:
\begin{enumerate}
    \item $\gcd(x^4+x^2+1, x^4-x^2-2x-1, x^3-1)$
    \item $\gcd(x^3+2x^2-x-2, x^3-2x^2-x+2, x^3-x^2-4x+4)$
\end{enumerate}
\end{exercise}
\begin{proof}
\begin{enumerate}
    \item Using the command 
    \begin{verbatim}
        PolynomialGCD[x^4+x^2+1, x^4-x^2-2x-1, x^3-1],
    \end{verbatim}
    on Wolfram Alpha, we obtain $\gcd(f_1, f_2, f_3)=x^2+x+1$.
    \item Using the command 
    \begin{verbatim}
        PolynomialGCD[x^3+2x^2-x-2, x^3-2x^2-x+2, x^3-x^2-4x+4],
    \end{verbatim}
    on Wolfram Alpha, we obtain $\gcd(f_1, f_2, f_3)=x-1$.
\end{enumerate}
\end{proof}

\begin{exercise}{9}
Use the method described in the text to decide whether $x^2-4$ is an element of the ideal $\brackets{x^3+x^2-4x-4, x^3-x^2-4x+4,x^3-2x^2-x+2}$.
\end{exercise}
\begin{proof}
To do this, we first use the command 
\begin{verbatim}
        PolynomialGCD[x^3+x^2-4x-4, x^3-x^2-4x+4,x^3-2x^2-x+2],
\end{verbatim}
on Wolfram Alpha to obtain the gcd of the 3 polynomials: $x-2$. Since $x^2-4 = (x-2)(x+2)$, then we know that $x^2-4$ belongs to the ideal, as it was to be shown.
\end{proof}

\begin{exercise}{10}
Give pseudocode for an algorithm that has input $f,g\in k[x]$ and output $h,A,B\in k[x]$ where $h =\gcd(f,g)$ and $Af+Bg=h$. Hint: The idea is to add variables $A,B,C,D$ to the algorithms so that $Af+Bg =h$ and $Cf+Dg =s$ remain true at every step of the algorithm. Note that the initial values of $A,B,C,D$ are $1,0,0,1$ respectively. You may find it useful to let $\text{quotient}(f,g)$ denote the quotient of $f$ on division by $g$,i.e., if the division algorithm yields $f =qg+r$, then $q =\text{quotient}(f,g)$.
\end{exercise}
\begin{proof}
We get:
\begin{center}
\begin{algorithmic}
\STATE $A \gets 1$
\STATE $h \gets f$
\STATE $C \gets 0$
\STATE $D\gets g$
\WHILE{$D\neq 0$}
    \STATE $Q = \text{quotient}(h,D)$
    \STATE $T = \text{remainder}(h,D)$
    \STATE $S = A - QC$
    \STATE $A = C$
    \STATE $h = D$
    \STATE $C = S$
    \STATE $D = T$
\ENDWHILE
\STATE $B = (h - fA)/g$
\end{algorithmic}
\end{center}
\end{proof}

\begin{exercise}{11}
In this exercise we will study the one-variable case of the consistency problem from Section 2. Given $f_1,\dots,f_s\in k[x]$, this asks if there is an algorithm to decide whether $\bV(f_1,\dots,f_s)$ is non-empty. We will see that the answer is yes when $k=\C$.
\begin{enumerate}
    \item Let $f\in\C[x]$ be a nonzero polynomial. Then use Theorem 7 of Section 1 to show that $\bV(f) =\emptyset$ if and only if $f$ is constant.
    \item If $f_1,\dots,f_s\in\C[x]$, prove $\bV(f_1,\dots,f_s) =\emptyset$ if and only if $\gcd(f_1,\dots,f_s) =1$.
    \item Describe (in words, not pseudocode) an algorithm for determining whether or not $\bV(f_1,\dots,f_s)$ is nonempty.
\end{enumerate}
When $k=\R$, the consistency problem is much more difficult. It requires giving an algorithm that tells whether a polynomial $f\in\R[x]$ has a real root.
\end{exercise}
\begin{proof}
\begin{enumerate}
    \item Assume first that $f$ is nonconstant. Then Theorem $7$ of \S 1 implies that $f$ has a root, and thus $\bV(f)$ is nonempty. On the other hand, if $f$ is nonzero and constant, then clearly it has no roots, and thus $\bV(f) = \emptyset$.
    \item We know that
    \begin{eqnarray*}
        \bV(f_1,...,f_s)
        & = & \bV(\langle f_1,...,f_s\rangle)\\
        & = & \bV(\langle \gcd(f_1,...,f_s)\rangle)\\
        & = & \bV(\gcd(f_1,...,f_s)).
    \end{eqnarray*}
    Thus from part (a) follows that $\bV(f_1,...,f_s)$ is empty if and only if $\gcd(f_1,...,f_s)$ is constant. Since the gcd is well-defined up to a multiplicative constant, this is equivalent to saying $\gcd(f_1,...,f_s) = 1$.
    \item We compute $g = \gcd(f_1,...,f_s)$ using the algorithm of Exercise $7$. Then we check whether this is a nonzero constant.
\end{enumerate}
\end{proof}

\begin{exercise}{12}
This exercise will study the one-variable case of the Nullstellensatz problem from Section 4, which asks for the relation between $\bI(\bV(f_1,\dots,f_s))$ and $\brackets{f_1,\dots,f_s}$ when $f_1,\dots,f_s\in\C[x]$. By using gcd's, we can reduce to the case of a single generator. So, in this problem, we will explicitly determine $\bI(\bV(f))$ when $f\in\C[x]$ is a nonconstant polynomial. Since we are working over the complex numbers, we know by Exercise 1 that $f$ factors completely, i.e., $f=c(x-a_1)^{r_1}\dots(x-a_l)^{r_l}$, where $a_1,\dots,a_l\in\C$ are distinct and $c\in\C\setminus\set{0}$. Define the polynomial $f_{\text{red}}=c(x-a_1)\dots(x-a_l)$. The polynomials $f$ and $f_{\text{red}}$ have the same roots, but their multiplicities may differ. In particular, all roots of $f_{\text{red}}$ have multiplicity one. We call $f_{\text{red}}$ the reduced or square-free part of $f$. The latter name recognizes that $f_{\text{red}}$ is the square-free factor of $f$ of largest degree.
\begin{enumerate}
    \item Show that $\bV(f)=\set{a_1,\dots,a_l}$.
    \item Show that $\bI(\bV(f))=\brackets{f_{\text{red}}}$.
\end{enumerate}
Whereas part 2 describes $\bI(\bV(f))$, the answer is not completely satisfactory because we need to factor $f$ completely to find $f_{\text{red}}$. In exercises 13, 14 and 15 we will show how to determine $f_{\text{red}}$ without any factoring.
\end{exercise}
\begin{proof}
\begin{enumerate}
    \item Take $a_i$ in the conjectured variety of $f$. Since $f=c(x-a_1)^{r_1}\dots(x-a_i)^{r_i}\dots(x-a_l)^{r_l}$, then $f(a_i)=c(a_i-a_1)^{r_1}\dots 0\dots(a_i-a_l)^{r_l}=0$. Furthermore, if $b\neq a_i$ for all $i$, then $b-a_i\neq 0$ for all $i$, so that $f(b)=c(b-a_1)^{r_1}\dots(b-a_l)^{r_l}\neq 0$, proving that there are no more elements in the conjectured variety. Hence $\bV(f)=\set{a_1,\dots,a_l}$.
    \item Since $\brackets{f_{\text{red}}}=\set{\sum_i^nh_if_{\text{red}}^i: h_i\in\C[x]}$, and $f_{\text{red}}(a_i=0$ for all $a_i\in\bV(f)$ (adapting the proof from above), then $\brackets{f_{\text{red}}}\subseteq\bI(\bV(f))$. 
    
    To see there are no additional polynomials in $\bI(\bV(f))$, suppose $g\notin\brackets{f_{\text{red}}}$, and divide $g$ by $f_{\text{red}}$: $g=hf_{\text{red}}+r$ where $0\leq\deg r<\deg f_{\text{red}}$. Now we claim $0 =g(a_i) =h(a_i)f_{\text{red}}(a_i)+r(a_i) =r(a_i)$ for all $a_i$. But if we factorise $r$ we obtain $r=c'(x-a_1)\dots(x-a_{j-1})(x-a_{j+1})(x-a_l)$ for some $j$, otherwise $\deg r=\deg f_{\text{red}}$, but this implies that $a_j-a_i\neq 0$ for all $i$, so that $r$ does not vanish at $a_j$, giving us a contradiction. Hence $\bI(\bV(f))=\brackets{f_{\text{red}}}$, as it was to be proven.
\end{enumerate}
\end{proof}

\begin{exercise}{13}
We will study the formal derivative of $f=c_0x^n+c_1x^{n-1}+\dots+c_{n-1}x+c_n\in\C[x]$. The formal derivative is defined by the usual formulas from calculus:
\[
f'=nc_0x^{n-1}+(n-1)c_1x^{n-2}+\dots+c_{n-1}+0.
\]
Prove that the following rules of differentiation apply:
\begin{align*}
    (af)' =& af',\, \text{ when } a\in\C,\\
    (f+g)' =& f' + g',\\
    (fg)' =& f'g + fg'.
\end{align*}
\end{exercise}
\begin{proof}
\begin{enumerate}
    \item We have,
    \begin{align*}
        (af)' =& (a[c_0x^n+c_1x^{n-1}+\dots+c_{n-1}x+c_n])'\\ 
        =& (ac_0x^n+ac_1x^{n-1}+\dots+ac_{n-1}x+ac_n)'\\
        =& nac_0x^{n-1}+(n-1)ac_1x^{n-2}+\dots+ac_{n-1}\\ =& a(nc_0x^{n-1}+(n-1)c_1x^{n-2}+\dots+c_{n-1}) =af',
    \end{align*}
    as required.
    \item Furthermore,
    \begin{align*}
        (f+g)' =& (c_0x^n+c_1x^{n-1}+\dots+c_{n-1}x+c_n\\ &+b_0x^m+b_1x^{m-1}+\dots+b_{m-1}x+b_m)'\\
        =& nc_0x^{n-1}+(n-1)c_1x^{n-2}+\dots+c_{n-1}\\
        &+ nb_0x^{n-1}+(n-1)b_1x^{n-2}+\dots+b_{m-1}\\
        =& f' + g',
    \end{align*}
    as required.
    \item Finally (notice the changed notation with respect to the previous two exercises),
    \begin{align*}
        (fg)' =& (\sum_{l=0}^{m+n}a_lx^l)',\text{ where }a_l=\sum_{j,k: j+k=l}c_jb_k\\
        =& \sum_{l=1}^{m+n}la_lx^{l-1}\\
        =& (\sum_{l=1}^{m}lc_lx^{l-1})(\sum_{l=0}^{n}b_lx^{l}) + (\sum_{l=0}^{m}c_lx^{l})(\sum_{l=1}^{n}lb_lx^{l-1})\\
        =& f'g + g'f,
    \end{align*}
    as required.
\end{enumerate}
\end{proof}

\begin{exercise}{14}
In this exercise we will use the differentiation properties of exercise 13 to compute $\gcd(f,f')$ when $f\in\C[x]$.
\begin{enumerate}
    \item Suppose $f=(x-a)^rh$ in $\C[x]$, where $r\geq 1$ and $h(a)\neq 0$. Then prove that $f'=(x-a)^{r-1}h_1$, where $h_1\in\C[x]$ does not vanish at $a$. Hint: Use the product rule.
    \item Let $f=c(x-a_1)^{r_1}\dots(x-a_l)^{r_l}$ be the factorisation of $f$, where $a_1,\dots,a_l$ are distinct. Prove that $f'$ is a product $f'=(x-a_1)^{r_1-1}\dots(x-a_l)^{r_l-1}H$, where $H\in\C[x]$ is a polynomial vanishing at none $a_1,\dots,a_l$.
    \item Prove that $\gcd(f,f')=(x-a_1)^{r_1-1}\dots(x-a_l)^{r_l-1}$.
\end{enumerate}
\end{exercise}
\begin{proof}
\begin{enumerate}
    \item We get from the product rule that
    \begin{eqnarray*}
        f'
        & = & r(x-a)^{r-1} h + (x-a)^r h'\\
        & = & (rh + (x-a) h') (x-a)^{r-1}\\
        & := & h_1 (x-a)^{r-1}.
    \end{eqnarray*}
    Note that
    $$h_1(a) = rh(a) + (a-a)h'(a) = rh(a)\neq 0.$$
\end{enumerate}
\end{proof}

\begin{exercise}{15}
Consider the square-free part $f_{\text{red}}$ of a polynomial $f\in\C[x]$ defined in Exercise 12.
\begin{enumerate}
    \item Use Exercise 14 to prove that $f_{\text{red}}$ is given by the formula
    \[
    f_{\text{red}} =\frac{f}{\gcd(f,f')}.
    \]
    The virtue of this formula is that it allows us to find the square-free part without factoring $f$. This allows for much quicker computations.
    \item Use a computer algebra system to find the square-free part of the polynomial 
    \[
    x^11-x^10+2x^8-4x^7+3x^5-3x^4+x^3+3x^2-x-1.
    \]
\end{enumerate}
\end{exercise}
\begin{proof}
fill
\end{proof}

\begin{exercise}{16}
Use exercises 12 and 15 to describe (in words, not pseudocode) an algorithm whose input consists of polynomials $f_1,\dots,f_s\in\C[x]$ and whose output consists of a basis of $\bI(\bV(f_1,\dots,f_s))$. It is more difficult to construct such an algorithm when dealing with polynomials of more than one variable.
\end{exercise}
\begin{proof}
fill
\end{proof}

\begin{exercise}{17}
17 (use a computer algebra system)
Find a basis for the ideal $\bI(\bV(x^5-2x^4+2x^2-x, x^5-x^4-2x^3+2x^2+x-1))$.
\end{exercise}
\begin{proof}
fill
\end{proof}