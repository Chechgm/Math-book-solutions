\subsection{Complete metric spaces}

13

26* Some nice counterexamples for intuition
27* Some nice counterexamples for intuition 

31* Infinite dimensional triangle inequality!
33C An example of a normed space which is not complete

\begin{exercise}{12}
Let $A$ be a subset of an arbitrary metric space $(M,d)$.
If $(A,d)$ is complete, show that $A$ is closed in $M$.
\end{exercise}
\begin{proof}
Let $(x_n)$ be a convergent sequence in $A$.
Then, $(x_n)$ is Cauchy.
Since $A$ is complete, then $(x_n)$ converges to a point in $A$.
Thus $A$ is closed.
\end{proof} 

\begin{exercise}{13}
Show that $\R$ endowed with the metric $\rho(x,y)=\absoluteValue{\arctan x-\arctan y}$ is not complete.
How about if we try $\tau(x,y)=\absoluteValue{x^3-y^3}$?
\end{exercise}
\begin{proof}
($\arctan$)
Consider the sequence given by $x_n = n$.
We have that $x_n$ is Cauchy under the $\arctan$ metric, but $\arctan n\to \pi/2$, which is not in the image of $\arctan$, and thus it is not complete.

(Cubic)
The cubic metric is complete.
Fix $\epsilon>0$, and let $(x_n)$ be Cauchy under the cubic metric, so that for a specific $N\in\N$, for $n,m>N$ it holds that $\absoluteValue{x_n^3 - x_m^3}<\epsilon$.
We have
\begin{align*}
    \absoluteValue{x_n-x_m}
    \leq& \absoluteValue{x_n-x_m}\absoluteValue{x_n^2+x_nx_m+x_m^2}\\
    =& \absoluteValue{x_n^3-x_m^3}
    < \epsilon.
\end{align*}
That is, $(x_n)$ is also Cauchy under the usual metric of $\R$, so that $x_n\to x$ under such metric.
Since $(x_n)$ converges, then it is bounded by a real number, say $M$.
Let $N\in\N$ be such that whenever $n>N$, it holds that $\absoluteValue{x_n-x}<\epsilon/(M^2+M\absoluteValue{x}+\absoluteValue{x}^2)$.
We have
\begin{align*}
    \absoluteValue{x_n^3-x^3}
    =& \absoluteValue{x_n-x}\absoluteValue{x_n^2+x_nx+x^2}\\
    \leq& \absoluteValue{x_n-x}[\absoluteValue{x_n}^2 + \absoluteValue{x_n x} + \absoluteValue{x}^2]\\
    \leq& \absoluteValue{x_n-x}[M^2 + M\absoluteValue{x} +\absoluteValue{x}^2]
    < \epsilon,
\end{align*}
so that $(x_n)$ converges to $x^3$ under the cubic metric, and thus $\R$ is complete under that metric too.

Take cauchy in tau. This is a bounded subset in (R, tau)
show that this is then also bounded in (R, usual)
so it has a convergent subsequence in (R, usual) and thus also in (R, tau) 
cauchy with convergent subsequence is convergent
\end{proof} 

\begin{exercise}{15}
Prove or disprove:
If $M$ is complete and $f:(M,d)\to (N,\rho)$ is continuous, then $f(M)$ is complete.
\end{exercise}
\begin{proof}
This is not true.
We know that $\R$ is complete, and homeomorphic to $(0,1)$ which is not.
Thus for the homeomorphism, $f$ between $\R$ and the open unit interval, it doesn't hold that $f(\R)$ is complete.
\end{proof} 

\begin{exercise}{16}
Prove that $\R^n$ is complete under any of the norms $\norm{\cdot}_1, \norm{\cdot}_2,$ or $\norm{\cdot}_\infty$.
[This is interesting because completeness is not usually preserved by the mere equivalence of metrics.
Here we used the fact that all of the metrics involved are generated by norms.
Specifically, we need the norms in question to be equivalent as functions:
$\norm{\cdot}_\infty \leq \norm{\cdot}_2 \leq \norm{\cdot}_1 \leq n\norm{\cdot}_\infty$.
As we will see later, any two norms on $\R^n$ are comparable this way].
\end{exercise}
\begin{proof}
Let $\epsilon>0$ and $(x_n)$ be a Cauchy sequence in $\R^n$, so that there exists $K\in\N$ such that whenever $k,l>K$, it holds that $\norm{x_k-x_l}_\infty < \epsilon$.
Thus for all $i\in \set{1,\dots,n}$, we have that $\absoluteValue{x_n^i-x_m^i}<\epsilon$, meaning that for all $i$, $(x^i_n)$ is Cauchy in $\R$ and hence it converges to $x^i$ by the completeness of $\R$.

Given this convergence, choose an $K\in\N$ (this is different from the $K$ above), such that whenever $k>K$, it holds that $\absoluteValue{x^i_k-x^i}<\epsilon$ for all $i$.
Let $x=(x^i)$, to see $(x_n)\to x$, notice that $\norm{x_k-x}_\infty = \max_i\absoluteValue{x_k^i-x^i} < \epsilon$, as required.
\end{proof} 

\begin{exercise}{17}
Given metric spaces $N$ and $M$, show that $M\times N$ is complete if and only if both $N$ and $M$ are complete.
\end{exercise}
\begin{proof}
($\Rightarrow$)
Suppose $M\times N$ is complete, so that any Cauchy sequence in $M\times N$ converges to a point in $M\times N$ under $\norm{\cdot}_\infty$.
Let $\epsilon>0$, the sequence $(x^N_k)$ be Cauchy in $N$ and $(x^M_k)$ Cauchy in $M$.
Hence, there exists $K\in\N$ with $d_N(x^N_k,x^N_l)<\epsilon$, and $d_M(x^M_k,x^M_l)<\epsilon$ whenever $k,l>K$.
We have that the sequence $(x_k) = (x^M_k,x^N_k)$ is Cauchy in $M\times N$ and by assumption it converges to $x=(x^N,x^M)$ under $\norm{\cdot}_\infty$.
We have 
\begin{align*}
    d_N(x^N_k,x^N) \leq \max_{i\in\set{N,M}}d_i(x^i_k,x^i) = \norm{x_k,x}_\infty < \epsilon,    
\end{align*}
and the same holds replacing $d_N(x^N_k,x^N)$ for $d_M(x^M_k,x^M)$, so that both $(x^N_k)$ and $(x^M_k)$ converge, as required.

($\Leftarrow$)
Suppose $N$ and $M$ are complete.
Let $\epsilon>0$ and $(x_k)$ be Cauchy in $M\times N$, so that we can find a $K\in\N$ with $\norm{x_k-x_l}_\infty<\epsilon$, whenever $k,l>K$.
As in the previous exercise, we have that both $d_N(x^N_k, x^N_l)<\epsilon$ and $d_M(x^M_k, x^M_l)<\epsilon$, and given that $N$ and $M$ are complete, the sequences $(x^N_k)$ and $(x^M_k)$ converge to, say $x^N$ and $x^M$. 

Let $x=(x^N, x^M)$, and choose $K\in\N$ (different from the one above) so that whenever $k>K$ it holds that $d_N(x^N_k, x^N)<\epsilon$ and $d_M(x^M_k, x^M)<\epsilon$.
We have that $\norm{x_k-x}_\infty = \max_{i\in \set{N,M}}d_i(x^i_k-x^i) < \epsilon$, so that $(x_k)$ converges, as required.
\end{proof} 

\begin{exercise}{18}
Fill in the details of the proofs that $l_1$ and $l_\infty$ are complete.
\end{exercise}
\begin{proof}
($l_1$)
Suppose $(f_n)$ is a Cauchy sequence in $l_1$.
Then for $\epsilon>0$, there exists an $N\in\N$, so that whenever $n,m>N$, it holds that $\norm{f_n-f_m}_1 = \sum_k \absoluteValue{f_n(k)-f_m(k)} < \epsilon$.
Thus, for all $k$, $f_n(k)$ is a Cauchy sequence and because $f_n(k)$ is in $\R$ (or $\C$) it converges, say $f_n(k)\to f(k)$. 
Our candidate limit of $l_1$ will be $f$, with $f(k)$ defined as above.

To see $f\in l_1$, notice that as $(f_n)$ is Cauchy, then by exercise 3.36, it is bounded by a constant $B$, and so $\sum_k^K \absoluteValue{f(k)} = \lim_{n\to\infty} \sum_k^K \absoluteValue{f_n(k)} \leq B$.
Since this holds for all $K$, we get that $\norm{f}_1 = \sum_k^\infty \absoluteValue{f(k)} < B$;
that is $f\in l_1$.

Finally, $f_n\to f$.
As above, we have that for all $K$, $\sum_k^K \absoluteValue{f_n(k)-f(k)} = \lim_{m\to \infty} \sum_k^K \absoluteValue{f_n(k)-f_m(k)} < \epsilon$, so that $\norm{f_n(k)-f(k)}_1 = \sum_k^\infty \absoluteValue{f_n(k)-f(k)} < \epsilon$ by the order limit Theorem.

($l_\infty$)
Let $(f_n)$ be a Cauchy sequence in $l_\infty$.
Thus for all $\epsilon>0$, there exists an $N\in\N$, so that whenever $n,m>N$, it holds that $\norm{f_n-f_m}_\infty = \sup_k\absoluteValue{f_n(k)-f_m(k)} < \epsilon$.
That is, for all $k$, $(f_n(k))$ is Cauchy  in $\R$ or $\C$ and thus converges, say $f_n(k)\to f(k)$.
Our candidate limit will be $f$, where $f(k)$ is as defined above.

To see $f\in l_\infty$, notice that for the $n$ defined above, we have 
\begin{align*}
    \norm{f}_\infty 
    =& \sup_k \absoluteValue{f(k)}\\ 
    =& \sup_k \absoluteValue{f(k) - f_n(k) + f_n(k)}\\
    \leq& \sup_k\absoluteValue{f(k) - f_n(k)} + \sup_k\absoluteValue{f_n(k)}\\
    <& \epsilon + B.
\end{align*}
Where $\sup_k\absoluteValue{f_n(k)}<B$, because $(f_n)\in l_\infty$.

Finally, we prove that $f_n\to f$.
To see this, we have $\norm{f_n-f}_\infty = \sup_k \absoluteValue{f_n(k) - f(k)} < \epsilon$, because for each $k$, $f_n(k)\to f(k)$, as we have argued above.
Thus $l_\infty$ is complete. 
\end{proof} 

\begin{exercise}{19}
Prove that $c_0$ is complete by showing that $c_0$ is closed in $l_\infty$.
[Hint: if $(f_n)$ is a sequence in $c_0$ converging to $f\in l_\infty$, note that $\absoluteValue{f(k)} \leq \absoluteValue{f(k)-f_n(k)} + \absoluteValue{f_n(k)}$.
Now choose $n$ so that the $\absoluteValue{f(k)-f_n(k)}$ is small independent of $k$]. 
\end{exercise}
\begin{proof}
Following the hint, suppose $f_n\to f$ under $\norm{\cdot}_\infty$.
That is, for all $\epsilon>0$, there exists an $N\in\N$, such that whenever $n>N$, it holds that $\norm{f_n-f} = \sup_k\absoluteValue{f_n(k)-f(k)} < \epsilon/2$.
Likewise, since $f_n\in c_0$, then $f(k) \to 0$, so that we can find an $K\in\N$ such that whenever $k>K$, it holds that $\absoluteValue{f_n(k)} <\epsilon/2$ (this holds for all $n$, so it holds for the $n$ chosen above).
We have
\begin{align*}
    \absoluteValue{f(k)} 
    \leq& \absoluteValue{f(k) + f_n(k) - f_n(k)}\\
    \leq& \absoluteValue{f(k) - f_n(k)} + \absoluteValue{f_n(k)}\\
    \leq& 2\epsilon/2 = \epsilon,
\end{align*}
so that $f(k)\to 0$, and thus $f\in c_0$, as required.

Now since $c_0$ is closed in $l_\infty$ which is a complete space, then by Theorem 7.9, $c_0$ is complete.
\end{proof} 

\begin{exercise}{20}
If $(x_n)$ and $(y_n)$ are Cauchy in $(M,d)$, show that $(d(x_n,y_n))^\infty_{n=1}$ is Cauchy in $\R$.
\end{exercise}
\begin{proof}
Let $\epsilon>0$ and let $N$ be such that whenever $n,m>N$, it holds $d(x_n,x_m)<\epsilon/2$ and $d(y_n,y_m)<\epsilon/2$.
We have
\begin{align*}
    d(x_n,y_n)-d(x_m,y_m)
    \leq& d(x_n,x_m) + d(x_m, y_n) - d(x_m,y_m)\\
    \leq& d(x_n,x_m) + d(y_m, y_n) + d(x_m,y_m) - d(x_m,y_m)\\
    <& 2\epsilon/2 = \epsilon.
\end{align*}
Likewise, we can obtain that $d(x_m,y_m)-d(x_n,y_n)<\epsilon$, which is the same as $d(x_n,y_n)-d(x_m,y_m)>-\epsilon$.
Putting those together, we get that $\absoluteValue{d(x_n,y_n)-d(x_m,y_m)}<\epsilon$, so that $(d(x_n,y_n))^\infty_{n=1}$ is Cauchy.
\end{proof} 

\begin{exercise}{21}
If $(M,d)$ is complete prove that two Cauchy sequences $(x_n)$ and $(y_n)$ have the same limit if and only if $d(x_n,y_n)\to 0$.
\end{exercise}
\begin{proof}
($\Rightarrow$)
Suppose $(x_n)$ and $(y_n)$ have the same limit, say $a$.
We have
\begin{align*}
    \absoluteValue{d(x_n,y_n)}
    =& d(x_n,y_n)\\
    \leq& d(x_n, a) + d(a, y_n) \to 0,
\end{align*}
since both $d(x_n,a)\to 0$ and $d(y_n,a)\to 0$.

($\Leftarrow$)
We will prove this by contrapositive.
Suppose $x_n\to a$ and $y_n\to b$, for $a\neq b$ and consider the candidate convergence $d(x_n,y_n)\to d(a,b)\neq 0$.
Fix $\epsilon>0$.
Since $x_n\to a$ and $y_n\to b$, we can find $N\in\N$, such that whenever $n>N$, it holds that both $d(x_n,a)<\epsilon/2$ and $d(y_n,b)<\epsilon/2$.
Thus, let $n>N$.
We have
\begin{align*}
    d(x_n,y_n) - d(a,b)
    \leq& d(x_n,a) + d(a,y_n) - d(a,b)\\
    \leq& d(x_n,a) + d(a,b) + d(b,y_n) - d(a,b)\\
    \leq& d(x_n, a) + d(b,y_n) < 2\epsilon/2 = \epsilon.
\end{align*}

Likewise
\begin{align*}
    d(a,b) - d(x_n,y_n)
    \leq& d(a,x_n) + d(b,x_n) - d(x_n,y_n)\\
    \leq& d(a,x_n) + d(x_n,y_n) + d(b,y_n) - d(x_n,y_n)\\
    \leq& d(a,x_n) + d(b,y_n) < 2\epsilon/2 = \epsilon,
\end{align*}
which is the same as $d(x_n,y_n)-d(a,b)>-\epsilon$.

Putting these inequalities together we get that $\absoluteValue{d(x_n,y_n)-d(a,b)}<\epsilon$, as desired.
\end{proof} 

\begin{exercise}{25}
True or False?
If $f:\R\to\R$ is continuous and $(x_n)$ is Cauchy, then $(f(x_n))$ is Cauchy.
Examples?
How about if we insist that $f$ be strictly increasing?
Show that the answer is ``True'' if $f$ is Lipschitz.
\end{exercise}
\begin{proof}
The answer is true.
$(x_n)$ Cauchy in $\R$ is convergent, so that $(f(x_n))$ is convergent in $\R$ too and thus Cauchy.
An obvious example is $f(x)=x$ and $(x_n)=1/n$, $f$ is continuous and $(x_n)=(f(x_n))$ is Cauchy.
The answer does not change if $f$ is strictly increasing.

For the Lipschitz result, let $(x_n)$ be Cauchy, let $M$ be the Lipschitz constant of $f$.
Let $N$ be such that whenever $n,m>N$, it is the case that $M\absoluteValue{x_n-x_m}<\epsilon$.
We have $\absoluteValue{f(x_n)-f(x_m)} \leq M\absoluteValue{x_n-x_m} < \epsilon$, so that $(f(x_n))$ is Cauchy, as required.
\end{proof} 

\begin{exercise}{26}
fill
\end{exercise}
\begin{proof}
fill
\end{proof} 

\begin{exercise}{27}
fill
\end{exercise}
\begin{proof}
fill
\end{proof} 

\begin{exercise}{31}
fill
\end{exercise}
\begin{proof}
fill
\end{proof} 

\begin{exercise}{33}
fill
\end{exercise}
\begin{proof}
fill
\end{proof} 
